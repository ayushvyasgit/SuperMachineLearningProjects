{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c401eba3-bf99-43a2-bbcd-9b76c4e9f7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b31ac8be-de0a-4dfe-8b00-03d76e3d18f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data =  [21,22,-108,31,-1,32,34,31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c35215aa-e50a-4e2a-97a8-5f715c012882",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_dataset = tf.data.Dataset.from_tensor_slices(sales_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2383435-ff1b-46d8-93b0-a9ce9f759842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "22\n",
      "-108\n",
      "31\n",
      "-1\n",
      "32\n",
      "34\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "for sale in tf_dataset.as_numpy_iterator():\n",
    "    print(sale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eac2d0d8-3fdf-4130-842f-824570f6b215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "22\n",
      "-108\n"
     ]
    }
   ],
   "source": [
    "for sale in tf_dataset.take(3).as_numpy_iterator():\n",
    "    print(sale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d0d790c-bbd2-4265-bdc1-427f9d3b0ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "22\n",
      "31\n"
     ]
    }
   ],
   "source": [
    " tf_dataset =  tf_dataset.filter(lambda x:x>0)\n",
    " for sale in tf_dataset.take(3):\n",
    "    print(sale.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "664f2cfe-3f43-491b-bef4-cc8364975494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "591224832\n",
      "833089536\n",
      "859963392\n",
      "564350976\n",
      "913711104\n",
      "833089536\n"
     ]
    }
   ],
   "source": [
    " tf_dataset =  tf_dataset.map(lambda x:x*72)\n",
    " for sale in tf_dataset:\n",
    "    print(sale.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29d70675-f8f9-47ea-a38b-9e639689ab86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "833089536\n",
      "564350976\n",
      "913711104\n",
      "591224832\n",
      "833089536\n",
      "859963392\n"
     ]
    }
   ],
   "source": [
    "tf_dataset = tf_dataset.shuffle(3)\n",
    "for sales in tf_dataset.as_numpy_iterator():\n",
    "    print(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c34b41e-b792-4c2c-a9ac-e7d6ee671a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x0000023C9CE9C180> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x0000023C9CE9C180>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names. The matching definitions were:\n",
      "Match 0:\n",
      "lambda x: x * 72\n",
      "\n",
      "Match 1:\n",
      "lambda x: x > 0\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x0000023C9CE9C180> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x0000023C9CE9C180>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names. The matching definitions were:\n",
      "Match 0:\n",
      "lambda x: x * 72\n",
      "\n",
      "Match 1:\n",
      "lambda x: x > 0\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x0000023C9CE00720> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x0000023C9CE00720>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names. The matching definitions were:\n",
      "Match 0:\n",
      "lambda x: x * 72\n",
      "\n",
      "Match 1:\n",
      "lambda x: x > 0\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x0000023C9CE00720> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x0000023C9CE00720>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names. The matching definitions were:\n",
      "Match 0:\n",
      "lambda x: x * 72\n",
      "\n",
      "Match 1:\n",
      "lambda x: x > 0\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "[1584 1512 2304]\n",
      "[2232 2448 2232]\n"
     ]
    }
   ],
   "source": [
    "tf_dataset = tf.data.Dataset.from_tensor_slices(sales_data)\n",
    "tf_dataset = tf_dataset.filter(lambda x:x>0).map(lambda x:x*72).shuffle(2).batch(3)\n",
    "for sales in tf_dataset.as_numpy_iterator():\n",
    "    print(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28e183f9-9032-44b3-a777-c20a3515d941",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Expected 'tf.Tensor(False, shape=(), dtype=bool)' to be true. Summarized data: b'No files matched pattern: images/*/*'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m images_ds \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mlist_files(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages/*/*\u001b[39m\u001b[38;5;124m'\u001b[39m , shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m images_ds\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(file\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:1329\u001b[0m, in \u001b[0;36mDatasetV2.list_files\u001b[1;34m(file_pattern, shuffle, seed, name)\u001b[0m\n\u001b[0;32m   1322\u001b[0m condition \u001b[38;5;241m=\u001b[39m math_ops\u001b[38;5;241m.\u001b[39mgreater(array_ops\u001b[38;5;241m.\u001b[39mshape(matching_files)[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   1323\u001b[0m                              name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatch_not_empty\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1325\u001b[0m message \u001b[38;5;241m=\u001b[39m math_ops\u001b[38;5;241m.\u001b[39madd(\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo files matched pattern: \u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1327\u001b[0m     string_ops\u001b[38;5;241m.\u001b[39mreduce_join(file_pattern, separator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m), name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1329\u001b[0m assert_not_empty \u001b[38;5;241m=\u001b[39m control_flow_assert\u001b[38;5;241m.\u001b[39mAssert(\n\u001b[0;32m   1330\u001b[0m     condition, [message], summarize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massert_not_empty\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1331\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcontrol_dependencies([assert_not_empty]):\n\u001b[0;32m   1332\u001b[0m   matching_files \u001b[38;5;241m=\u001b[39m array_ops\u001b[38;5;241m.\u001b[39midentity(matching_files)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\control_flow_assert.py:102\u001b[0m, in \u001b[0;36mAssert\u001b[1;34m(condition, data, summarize, name)\u001b[0m\n\u001b[0;32m    100\u001b[0m     xs \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mconvert_n_to_tensor(data)\n\u001b[0;32m    101\u001b[0m     data_str \u001b[38;5;241m=\u001b[39m [_summarize_eager(x, summarize) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m xs]\n\u001b[1;32m--> 102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mInvalidArgumentError(\n\u001b[0;32m    103\u001b[0m         node_def\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    104\u001b[0m         op\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    105\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to be true. Summarized data: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m    106\u001b[0m         (condition, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(data_str)))\n\u001b[0;32m    107\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(name, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAssert\u001b[39m\u001b[38;5;124m\"\u001b[39m, [condition, data]) \u001b[38;5;28;01mas\u001b[39;00m name:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Expected 'tf.Tensor(False, shape=(), dtype=bool)' to be true. Summarized data: b'No files matched pattern: images/*/*'"
     ]
    }
   ],
   "source": [
    "images_ds = tf.data.Dataset.list_files('images/*/*' , shuffle=False)\n",
    "\n",
    "for file in images_ds.take(5):\n",
    "    print(file.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c09a76d-9970-46a3-891d-971b14ece208",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'images_ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m images_ds \u001b[38;5;241m=\u001b[39m images_ds\u001b[38;5;241m.\u001b[39mshuffle(\u001b[38;5;241m200\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m images_ds\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(file\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'images_ds' is not defined"
     ]
    }
   ],
   "source": [
    "images_ds = images_ds.shuffle(200)\n",
    "for file in images_ds.take(3):\n",
    "    print(file.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d50dcebe-b3b9-40d9-aa7a-01613354bc14",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "closing parenthesis '}' does not match opening parenthesis '[' (138836830.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[18], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    class_names = [\"cat\",\"dog\"}\u001b[0m\n\u001b[1;37m                              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m closing parenthesis '}' does not match opening parenthesis '['\n"
     ]
    }
   ],
   "source": [
    "class_names = [\"cat\",\"dog\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7304931e-bc02-410e-b848-e1dbb48b2477",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'images_ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m images_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(images_ds)\n\u001b[0;32m      2\u001b[0m images_count\n",
      "\u001b[1;31mNameError\u001b[0m: name 'images_ds' is not defined"
     ]
    }
   ],
   "source": [
    "images_count = len(images_ds)\n",
    "images_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ca94497-3ba7-41ff-ad2f-7c7c82d54cae",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'images_count' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(images_count\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m0.8\u001b[39m)\n\u001b[0;32m      3\u001b[0m train_ds \u001b[38;5;241m=\u001b[39m images_ds\u001b[38;5;241m.\u001b[39mtake(train_size)\n\u001b[0;32m      4\u001b[0m test_ds  \u001b[38;5;241m=\u001b[39m images_ds\u001b[38;5;241m.\u001b[39mskip(train_size)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'images_count' is not defined"
     ]
    }
   ],
   "source": [
    "train_size = int(images_count*0.8)\n",
    "\n",
    "train_ds = images_ds.take(train_size)\n",
    "test_ds  = images_ds.skip(train_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e97738b5-eb7a-4b78-a0b6-0460fca4a0af",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(train_ds)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_ds' is not defined"
     ]
    }
   ],
   "source": [
    "len(train_ds) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "69a9e0b9-507d-44b6-813d-dfe52732f8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "    return file_path.split(\"\\\\\")[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e22477-558e-4fba-9100-2c8b9ad19aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "    import os \n",
    "    return tf.strings.split(file_path,os.path.sep)[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9defdae-0ef5-4b8f-b395-d751089614a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(file_path):\n",
    "    label = get_label(file_path)\n",
    "\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = tf.image.decode_jpeg(img)\n",
    "    img = tf.image.resize(img,[128,128])\n",
    "\n",
    "    return img , label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d4e64207-c43a-4488-b2bf-fda9cdf15c72",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m train_ds\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m4\u001b[39m):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(t\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_ds' is not defined"
     ]
    }
   ],
   "source": [
    "for t in train_ds.take(4):\n",
    "    print(t.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e83e3bd-4ae6-4ec8-af40-a7b79f2c9cea",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m train_ds\u001b[38;5;241m.\u001b[39mmap(process_image)\u001b[38;5;241m.\u001b[39mtake():\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(label)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_ds' is not defined"
     ]
    }
   ],
   "source": [
    "for label in train_ds.map(process_image).take():\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "55b694c1-9d38-422b-8d79-c8259a77b8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(image,label):\n",
    "    return image/255,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4197f3d6-599a-47af-8f5a-d7bdf9dcf97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.map(scale)\n",
    "for image, label in train_ds.take(5):\n",
    "    print(\"****Image: \",image.numpy()([0][0])\n",
    "    print(\"****Label: \",label.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
